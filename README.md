# Autism Sensory Trigger Journal (Video-Assisted)

**Privacy-preserving video-assisted sensory trigger journal with AI pattern detection to help caregivers identify environmental triggers for autism-related sensory sensitivities.**

## ğŸ¯ Problem Statement

Parents and educators struggle to identify consistent sensory triggers causing meltdowns or withdrawal in children with autism. Traditional text-based journaling is time-consuming and often misses subtle environmental patterns that only become visible when analyzed systematically over time.

## ğŸ’¡ Solution Overview

A digital journaling app where caregivers:
- **Upload short video clips** (30-90 seconds) capturing the environment and context
- **Log structured metadata**: Activity, location, observed stress level, duration
- **Receive AI-powered insights**: Pattern detection surfaces correlations between environmental factors (noise, light, crowd) and behavioral responses

**Key Design Principles:**
- âœ… **Privacy-first**: Raw video can be deleted after feature extraction; no facial recognition
- âœ… **Caregiver-in-the-loop**: AI assists, doesn't diagnose
- âœ… **Explainable insights**: Transparent correlations, not black-box predictions
- âœ… **Ethical & research-aligned**: Supports behavioral research and data-driven intervention design

## âœ¨ Features

### Completed (Demo UI)
- ğŸ¥ **Video upload interface** with preview
- ğŸ“ **Structured journal entry form** (activity, location, stress level, notes)
- ğŸ“Š **Patterns & Insights dashboard** showing:
  - Top sensory trigger patterns
  - Explainable correlations (noise, brightness, crowd motion)
  - Per-child sensory profiles
- ğŸ“… **Entry timeline** with visual stress indicators
- ğŸ‘¤ **Multi-child profile support**
- ğŸ”’ **Privacy consent flow** and ethics messaging
- ğŸ¨ **Accessible, caregiver-friendly UI**

### To Be Implemented

#### Backend (FastAPI)
- [ ] REST API endpoints for entries, patterns, profiles
- [ ] Video upload handling and storage (encrypted)
- [ ] Database schema (SQLite/PostgreSQL)
- [ ] Authentication & authorization
- [ ] File management (auto-delete after processing)

#### Video Processing Pipeline
- [ ] **Audio feature extraction** (librosa):
  - Volume levels (dB)
  - Noise spikes detection
  - Frequency band analysis
- [ ] **Visual environment features** (OpenCV):
  - Brightness/flicker detection
  - Motion density (crowd movement)
  - Color intensity analysis
- [ ] **Behavioral motion analysis** (MediaPipe):
  - Body motion intensity
  - Repetitive movement detection
  - Movement pattern tracking
- [ ] **Privacy safeguards**:
  - No facial recognition
  - Feature extraction â†’ delete raw video option
  - Encrypted storage if video must be retained

#### ML Layer (Scikit-learn)
- [ ] Feature vector construction from extracted signals
- [ ] K-means clustering for pattern grouping
- [ ] Correlation analysis (environment â†” stress)
- [ ] Pattern surfacing algorithms
- [ ] Export anonymized datasets for research

#### Integration & Testing
- [ ] Connect frontend to backend API
- [ ] End-to-end video processing flow
- [ ] ML pipeline testing with sample data
- [ ] Privacy compliance verification
- [ ] Performance optimization

## ğŸ›  Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | React + Vite |
| **Backend** | Python (FastAPI) - *To be implemented* |
| **Video Processing** | OpenCV, Librosa - *To be implemented* |
| **Pose Detection** | MediaPipe - *To be implemented* |
| **ML/AI** | Scikit-learn - *To be implemented* |
| **Database** | SQLite (prototype) / PostgreSQL - *To be implemented* |
| **Security** | Encrypted file storage - *To be implemented* |

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ and npm
- Python 3.9+ (for backend, when implemented)

### Frontend Setup (Current)

```bash
# Install dependencies
npm install

# Run development server
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

The app will be available at `http://localhost:5173`

### Backend Setup (To Be Implemented)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install fastapi uvicorn opencv-python librosa mediapipe scikit-learn

# Run server
uvicorn main:app --reload
```

## ğŸ“ Project Structure

```
autism-trigger-journal/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.jsx          # Main application component
â”‚   â”œâ”€â”€ App.css          # Application styles
â”‚   â”œâ”€â”€ main.jsx         # Entry point
â”‚   â””â”€â”€ index.css        # Global styles
â”œâ”€â”€ public/              # Static assets
â”œâ”€â”€ package.json         # Frontend dependencies
â”œâ”€â”€ README.md            # This file
â””â”€â”€ [backend/]           # To be created
    â”œâ”€â”€ main.py          # FastAPI app
    â”œâ”€â”€ models/          # Database models
    â”œâ”€â”€ api/             # API endpoints
    â”œâ”€â”€ ml/              # ML processing pipeline
    â””â”€â”€ video/           # Video processing utilities
```

## ğŸ” Privacy & Ethics

This project follows responsible AI principles:

- **No facial recognition**: Only body motion and environmental features are analyzed
- **Anonymized features**: Raw video can be deleted after feature extraction
- **Caregiver control**: All labeling and consent is caregiver-driven
- **Not diagnostic**: Tool assists pattern recognition, does not diagnose autism
- **Research-aligned**: Designed to support behavioral research and intervention design

## ğŸ“ Academic Value

- Supports behavioral research and data-driven intervention design
- Demonstrates privacy-preserving AI for sensitive healthcare applications
- Showcases explainable ML (transparent correlations vs black-box models)
- Caregiver-in-the-loop design pattern

## ğŸš§ Roadmap

### Phase 1: MVP (Current)
- âœ… Demo UI with mock data
- â³ Backend API skeleton
- â³ Basic video upload handling

### Phase 2: Core Features
- â³ Video processing pipeline
- â³ Feature extraction (audio, visual, motion)
- â³ Database integration
- â³ ML clustering implementation

### Phase 3: Advanced Features
- â³ Real-time pattern detection
- â³ Export functionality for research
- â³ Multi-environment comparison (home vs school)
- â³ Personalized intervention suggestions

### Phase 4: Production Ready
- â³ IRB-ready consent flow
- â³ Security audit
- â³ Performance optimization
- â³ User testing with caregivers

## ğŸ“ Contributing

This is a research/educational project. Contributions should:
- Maintain privacy-first principles
- Follow ethical AI guidelines
- Include clear documentation
- Respect caregiver and child privacy

## ğŸ“„ License

[Specify your license here]

## ğŸ™ Acknowledgments

Built with care for caregivers, educators, and researchers working to support children with autism and sensory sensitivities.

---

**Note**: This is a prototype/demo. The current UI uses simulated data for demonstration purposes. Full implementation requires backend, ML pipeline, and video processing components.
